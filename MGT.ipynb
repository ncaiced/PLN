{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fed3fe7-6ec9-4558-aab4-ad1da50ac50f",
   "metadata": {},
   "source": [
    "# Modelos de Generación de Texto - Natalia Caicedo \n",
    "\n",
    "<font size=\"4\">\n",
    "Revisión de modelos de generación de texto en la plataforma de hugginface, \"los modelos más populares para la tarea de generar texto son los basados en modelos GPT, dado que estos modelos no requieren etiquetas previas en su entrenamiento. Además, los modelos GPT son capaces de generar gran variedad de texto, desde codigo a historias completas.\" https://huggingface.co/tasks/text-generation. \n",
    "Ejemplos de modelos de generación de texto son _BertGeneration, DialoGPT, Longformer_. Sus diferencias se basan en cambios en los parámetros, bases de datos con los cuales se entrenan y enfoque en atención global o local. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced072d3-939b-4ae0-9119-501262f09d5c",
   "metadata": {},
   "source": [
    "# GODEL\n",
    "<font size=\"4\">\n",
    "GODEL es un modelo de dialogo pre-entrenado desarrollado por Microsoft. Frente a modelos anteriores, presenta la ventaja de una fase de 'grounded pre-training' con la cual se equipa para desarrollar conversaciones que requieren información externa a la conversación actual (bases de datos o ducumentos). \n",
    "Utiliza un transformer seq-to-seq para generar respuestas dado un historial de dialogo y un ambiente. El contexto $S$ y el ambiente $E$ son concatenados como una secuencia que será la entrada del modelo.\n",
    "\n",
    "![Imagen](https://www.marktechpost.com/wp-content/uploads/2022/06/GODEL-1024x533.png)\n",
    "\n",
    "El modelo se pre-entrena en 3 fases:\n",
    "\n",
    "1. Pre-entrenamiento lingüístico usando documentos web públicos para proporcionar la capacidad básica para la generación de texto. \n",
    "2. Pre-entrenamiento de diálogo sobre datos de diálogo público para mejorar el manejo de los modelos del comportamiento conversacional general.\n",
    "3. Pre-entrenamiento del contexto para permitir la generación de respuestas según el contexto.\n",
    "\n",
    "Formato de los datos:\n",
    "\n",
    "- Context: The context from session beginning to current turn.\n",
    "- Knowledge: External or environment state represented in plain text.\n",
    "- Reponse: The target agent respose. It can be a template, an api call or natural language\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa638c-5408-4e46-a5e9-c50eecac850a",
   "metadata": {},
   "source": [
    "![Imagen](https://winbuzzer.com/wp-content/uploads/2022/06/GODEL-Language-Model-Chart-Showing-Conversation-Flow.jpg.webp)\n",
    "\n",
    "_Imagen tomada del artículo [Microsoft’s GODEL Language Model Becomes Open Source](https://winbuzzer.com/2022/06/24/microsofts-godel-language-model-becomes-open-source-xcxwbn/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc5028-bb50-408c-8789-a4b4a18f9a57",
   "metadata": {},
   "source": [
    "### Ejemplo de aplicación modelo GODEL\n",
    "<font size=\"4\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5ea737-0596-4976-9142-937c49d30603",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a200c13-5a0f-4753-925c-7eed9c8d2d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalia/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/GODEL-v1_1-base-seq2seq\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/GODEL-v1_1-base-seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9ef29c-6e61-4983-9e33-76fb7a986902",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_examples = [\n",
    "    ('Instruction: given a dialog context, you need to response empathically.',\n",
    "     '', 'Does money buy happiness?', 'Chitchat'),\n",
    "    ('Instruction: given a dialog context, you need to response empathically.',\n",
    "     '', 'What is the goal of life?', 'Chitchat'),\n",
    "    ('Instruction: given a dialog context, you need to response empathically.',\n",
    "     '', 'What is the most interesing thing about our universe?', 'Chitchat'),\n",
    "     ('Instruction: given a dialog context and related knowledge, you need to answer the question based on the knowledge.', \n",
    "     '''Scooby-Doo is the eponymous character and protagonist of the animated television franchise of the same name, created in 1969 by the American animation company Hanna-Barbera.[1] He is a male Great Dane and lifelong companion of amateur detective Shaggy Rogers, with whom he shares many personality traits. He features a mix of both canine and human behaviors (reminiscent of other talking animals in Hanna-Barbera's series), and is treated by his friends more or less as an equal. Scooby often speaks in a rhotacized way, substituting the first letters of many words with the letter 'r'. His catchphrase is \"Scooby-Dooby-Doo!\"\n",
    "     ''',\n",
    "     'What kind of animal is scooby from scooby doo?', 'Conversational Question Answering'\n",
    "     ),\n",
    "     ('Instruction: given a dialog context and related knowledge, you need to answer the question based on the knowledge.', \n",
    "     '''Subject: faa demos \n",
    "    Dan: PM Team, Attached are some general ideas and issues around developing new demos for our new target markets. Please review and provide feedback. Also, please provide links where we can learn more about various FAA applications. Thanx, Dan. \n",
    "    Alex: Dan, Thanks for putting the high level descriptions together. My questions are: *Is it practical to do an EAI demo given the inherent complexity of application integration? ... * Should we delay looking at Outlook for now?... *What do you think that timelines are developing these demos? ... Alex \n",
    "    Dan: Alex, Thanks for the feedback, please see my comments below:\n",
    "     ''',\n",
    "     'what does Dan ask PM team to do?', 'Conversational Question Answering'\n",
    "     ),\n",
    "     ('Instruction: given a dialog context and related knowledge, you need to answer the question based on the knowledge.', \n",
    "     '''Carlos Alcaraz, at just 19, completed an improbable journey on Sunday in Flushing Meadows as he defeated No. 5 Casper Ruud to win the 2022 US Open. Alcaraz came away with a 6-4, 2-6, 7-6, 6-2 win over Ruud to win his first career Grand Slam title.\n",
    "     \n",
    "     In doing so, Alcaraz became the second-youngest player to win a men's US Open title at 19 years, 129 days old, only trailing Pete Sampras. In addition, Alcaraz is the seventh youngest male or female to ever win a Grand Slam tournament. With the Grand Slam victory, Alcaraz becomes the No. 1 ranked player in the world. Additionally, the 19-year-old budding star is also the youngest player to ever be ranked as the world's No. 1 player.\n",
    "     ''',\n",
    "     'who won the 2022 US Open? EOS Carlos Alcaraz EOS how old?', 'Conversational Question Answering'\n",
    "     ),\n",
    "     (\n",
    "        'Instruction: given a dialog context and related knowledge, you need to response safely based on the knowledge.',\n",
    "        '''Over-the-counter medications such as ibuprofen (Advil, Motrin IB, others), acetaminophen (Tylenol, others) and aspirin.\n",
    "        ''',\n",
    "        'I have a headache, what should I do?', \"Grounded Response Generation\"\n",
    "     ),\n",
    "     (\n",
    "        'Instruction: given a dialog context and related knowledge, you need to response safely based on the knowledge.',\n",
    "        '''The best Stardew Valley mods PCGamesN_0 / About SMAPI\n",
    "        ''',\n",
    "        'My favorite game is stardew valley. stardew valley is very fun.', \"Grounded Response Generation\"\n",
    "     ),\n",
    "     (\n",
    "        'Instruction: given a dialog context and related knowledge, you need to response safely based on the knowledge.',\n",
    "        '''Wong Kar-wai BBS (born 17 July 1958) is a Hong Kong film director, screenwriter, and producer. His films are characterised by nonlinear narratives, atmospheric music, and vivid cinematography involving bold, saturated colours. A pivotal figure of Hong Kong cinema, Wong is considered a contemporary auteur, and ranks third on Sight & Sound's 2002 poll of the greatest filmmakers of modern times.[note 1] His films frequently appear on best-of lists domestically and internationally.\n",
    "        ''',\n",
    "        'My favorite director is wrong kar wai. i think in modern cinema there is no other director is is making the medium as cool', \"Grounded Response Generation\"\n",
    "     )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25de2f4-a349-4e74-8466-599db2050190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction, knowledge, dialog, top_p, min_length, max_length):\n",
    "    if knowledge != '':\n",
    "        knowledge = '[KNOWLEDGE] ' + knowledge\n",
    "    dialog = ' EOS '.join(dialog)\n",
    "    query = f\"{instruction} [CONTEXT] {dialog} {knowledge}\"\n",
    "\n",
    "    input_ids = tokenizer(f\"{query}\", return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids, min_length=int(\n",
    "        min_length), max_length=int(max_length), top_p=top_p, do_sample=True)\n",
    "    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(query)\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def api_call_generation(instruction, knowledge, query, top_p, min_length, max_length):\n",
    "\n",
    "    dialog = [\n",
    "        query\n",
    "    ]\n",
    "    response = generate(instruction, knowledge, dialog,\n",
    "                        top_p, min_length, max_length)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def change_example(choice):\n",
    "    choice_idx = int(choice.split()[-1]) - 1\n",
    "    instruction, knowledge, query, instruction_type = preset_examples[choice_idx]\n",
    "    return [gr.update(lines=1, visible=True, value=instruction), gr.update(visible=True, value=knowledge), gr.update(lines=1, visible=True, value=query), gr.update(visible=True, value=instruction_type)]\n",
    "\n",
    "def change_textbox(choice):\n",
    "    if choice == \"Chitchat\":\n",
    "        return gr.update(lines=1, visible=True, value=\"Instruction: given a dialog context, you need to response empathically.\")\n",
    "    elif choice == \"Grounded Response Generation\":\n",
    "        return gr.update(lines=1, visible=True, value=\"Instruction: given a dialog context and related knowledge, you need to response safely based on the knowledge.\")\n",
    "    else:\n",
    "        return gr.update(lines=1, visible=True, value=\"Instruction: given a dialog context and related knowledge, you need to answer the question based on the knowledge.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd378da8-4e71-4572-9b9e-0f88e0d57d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# GODEL: Large-Scale Pre-Training for Goal-Directed Dialog\")\n",
    "    gr.Markdown('''GODEL is a large open-source pre-trained language model for dialog. In contrast with its predecessor DialoGPT, GODEL leverages a new phase of grounded pretraining designed to better support finetuning phases that require information external to the current conversation (e.g., a database or document) to produce good responses. More information about this work can be found in the paper [GODEL: Large-Scale Pre-training for Goal-Directed Dialog.](https://www.microsoft.com/en-us/research/project/godel/)\n",
    ">Looking for a large open-source pre-trained language model for dialog? Look no further than GODEL! GODEL leverages a new phase of grounded pretraining designed to better support finetuning phases that require information external to the current conversation (e.g., a database or document) to produce good responses. So if you're looking for a language model that can help you produce better responses in a variety of situations, GODEL is the right choice for you!<p style=\"text-align:right\"> ------ a copy from GPT-3</p>''')\n",
    "\n",
    "    dropdown = gr.Dropdown(\n",
    "        [f\"Example {i+1}\" for i in range(9)], label='Examples')\n",
    "\n",
    "    radio = gr.Radio(\n",
    "        [\"Conversational Question Answering\", \"Chitchat\", \"Grounded Response Generation\"], label=\"Instruction Type\", value='Conversational Question Answering'\n",
    "    )\n",
    "    instruction = gr.Textbox(lines=1, interactive=True, label=\"Instruction\",\n",
    "                             value=\"Instruction: given a dialog context and related knowledge, you need to answer the question based on the knowledge.\")\n",
    "    radio.change(fn=change_textbox, inputs=radio, outputs=instruction)\n",
    "    knowledge = gr.Textbox(lines=6, label=\"Knowledge\")\n",
    "    query = gr.Textbox(lines=1, label=\"User Query\")\n",
    "\n",
    "    dropdown.change(change_example, dropdown, [instruction, knowledge, query, radio])\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            response = gr.Textbox(label=\"Response\", lines=2)\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            top_p = gr.Slider(0, 1, value=0.9, label='top_p')\n",
    "            min_length = gr.Number(8, label='min_length')\n",
    "            max_length = gr.Number(\n",
    "                64, label='max_length (should be larger than min_length)')\n",
    "\n",
    "    greet_btn = gr.Button(\"Generate\")\n",
    "    greet_btn.click(fn=api_call_generation, inputs=[\n",
    "                    instruction, knowledge, query, top_p, min_length, max_length], outputs=response)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c78c30-803b-4cf1-b0f2-6dc41a1a7c4b",
   "metadata": {},
   "source": [
    "### Configuración del modelo basado en T5\n",
    "<font size=\"4\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c0d575-1580-4cd7-92f0-a5dec5902100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"microsoft/GODEL-v1_1-large-seq2seq\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 4096,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 24,\n",
       "  \"num_heads\": 16,\n",
       "  \"num_layers\": 24,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.25.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32102\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/GODEL-v1_1-large-seq2seq\")\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80882df3-7e5e-4ec8-8fc8-0b3f258e6da0",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "Aquí cabe resaltar que GODEL está basado en modelos T5, T5 tiene una versión (MT5 - Multilingual Transformer model pre-trained on a dataset). Una aproximación es entrenar el modelo con conocimiento y contexto en español para verificar sus resultados. \n",
    "    \n",
    "Mayor información sobre los parámetros y el formato de los datos puede ser encontrado en el [GitHub del proyecto](https://github.com/microsoft/GODEL) o en el artículo presentado por Microsoft: [GODEL: Large-Scale Pre-Training for Goal-Directed Dialog](https://www.microsoft.com/en-us/research/uploads/prod/2022/05/2206.11309.pdf). \n",
    "\n",
    "Finalmente, se resalta de manera general que los desarrolladores implementaron tres tamaños del modelo: GODEL$_B$ con 220M parámetros, un encoder  y decoder de 12 capas cada uno y con embeddings de dimension 768, GODEL$_L$ con 770M parámetros, un encoder y decoder de 24 capas con embeddings de dimension 1024 y GODEL$_{XL}$ con 175B de parámetros. Los dos primeros tamaños están basados en T5 y T5-Large y su información se puede encontrar en los repositorios de huggingface para [GODEL$_B$](https://huggingface.co/microsoft/GODEL-v1_1-base-seq2seq?text=Hi.) y el [GODEL$_L$](https://huggingface.co/microsoft/GODEL-v1_1-large-seq2seq?text=Hey+my+name+is+Julien%21+How+are+you%3F) respectivamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e462b-73d9-4126-b394-8f3b728cd3f0",
   "metadata": {},
   "source": [
    "# Modelos de generación de texto en el contexto legal en español\n",
    "<font size=\"4\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf9b4c-88fe-45bc-9605-a64821594ef0",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "Por último, se hizo una revisión de algunos modelos del repositorio de huggingface entrenados con dominio legal en español, entre ellos se encuentra el modelo [RoBERTalex](https://huggingface.co/PlanTL-GOB-ES/RoBERTalex?text=La+ley+fue+%3Cmask%3E+finalmente.#model-description)  y [legal-longformer-base-8192-spanish](https://huggingface.co/mrm8488/legal-longformer-base-8192-spanish) los cuales estan pre-entrados con la base de datos de [Spanish Legal Domain Corpora](https://zenodo.org/record/5495529#.Y6m_j-zMK3I). El modelo RoBERTalex model esta pre-entrenado para uso en masked language, sin embargo puede afinarse para uso en otros contextos, el legal-longformer tiene el mismo propósito pero amplía el contexto que toma como referencia. from transformers import pipeline\n",
    "from pprint import pprint\n",
    "unmasker = pipeline('fill-mask', model='PlanTL-GOB-ES/RoBERTalex')\n",
    "pprint(unmasker(\"La ley fue <mask> finalmente.\"))from transformers import pipeline\n",
    "from pprint import pprint\n",
    "unmasker = pipeline('fill-mask', model='PlanTL-GOB-ES/RoBERTalex')\n",
    "pprint(unmasker(\"La ley fue <mask> finalmente.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96598726-92e2-4fd9-988e-c80d710cff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768e41c4-14aa-4764-a7e7-ccc0dfda915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c9e20-6b1c-48dc-a916-76868fc9933e",
   "metadata": {},
   "source": [
    "unmasker = pipeline('fill-mask', model='PlanTL-GOB-ES/RoBERTalex')\n",
    "pprint(unmasker(\"La ley fue <<mask>> finalmente.\"))\n",
    "\n",
    "[{'score': 0.21217258274555206,\n",
    "  'sequence': ' La ley fue modificada finalmente.',\n",
    "  'token': 5781,\n",
    "  'token_str': ' modificada'},\n",
    " {'score': 0.20414969325065613,\n",
    "  'sequence': ' La ley fue derogada finalmente.',\n",
    "  'token': 15951,\n",
    "  'token_str': ' derogada'},\n",
    " {'score': 0.19272951781749725,\n",
    "  'sequence': ' La ley fue aprobada finalmente.',\n",
    "  'token': 5534,\n",
    "  'token_str': ' aprobada'},\n",
    " {'score': 0.061143241822719574,\n",
    "  'sequence': ' La ley fue revisada finalmente.',\n",
    "  'token': 14192,\n",
    "  'token_str': ' revisada'},\n",
    " {'score': 0.041809432208538055,\n",
    "  'sequence': ' La ley fue aplicada finalmente.',\n",
    "  'token': 12208,\n",
    "  'token_str': ' aplicada'}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c23de-a247-4735-9031-f01ba1a7c2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
